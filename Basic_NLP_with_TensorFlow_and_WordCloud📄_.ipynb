{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Basic NLP with TensorFlow and WordCloudðŸ“„ .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "H5G6Uz9V86_M",
        "N3EXKutZ86_X",
        "GxQL3j0h86_p",
        "F3LT-5Md87AA",
        "5imyovGX87AU",
        "QraiuUe_87Av",
        "IT48Vy4n87A6",
        "4SyqAHyN87BE"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/Big_Data_Public/blob/master/Basic_NLP_with_TensorFlow_and_WordCloud%F0%9F%93%84_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5HaxC8586-W",
        "colab_type": "text"
      },
      "source": [
        "<a id='top'></a>\n",
        "<h1 style=\"text-align:center;font-size:200%;;\">Real or Not? NLP with Disaster Tweets</h1>\n",
        "<img src=\"https://dataxboost.files.wordpress.com/2018/03/nlp.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMblP-KL86-a",
        "colab_type": "text"
      },
      "source": [
        "## Competition Description\n",
        "* Twitter has become an important communication channel in times of emergency.\n",
        "The ubiquitousness of smartphones enables people to announce an emergency theyâ€™re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdTyFJMSL3lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdFoe1rQ86-b",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content!</h3>\n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#libraries\" role=\"tab\" aria-controls=\"profile\">Import Libraries<span class=\"badge badge-primary badge-pill\">1</span></a>\n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#load\" role=\"tab\" aria-controls=\"messages\">Load Data<span class=\"badge badge-primary badge-pill\">2</span></a>\n",
        "  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#visual\" role=\"tab\" aria-controls=\"settings\">Visualization of data<span class=\"badge badge-primary badge-pill\">3</span></a>\n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#word\" role=\"tab\" aria-controls=\"settings\">WordCloud<span class=\"badge badge-primary badge-pill\">4</span></a> \n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#clean\" role=\"tab\" aria-controls=\"settings\">Cleaning the text<span class=\"badge badge-primary badge-pill\">5</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#split\" role=\"tab\" aria-controls=\"settings\">Train and test Split<span class=\"badge badge-primary badge-pill\">6</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#model\" role=\"tab\" aria-controls=\"settings\"> Creating the Model<span class=\"badge badge-primary badge-pill\">7</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#eval\" role=\"tab\" aria-controls=\"settings\">Model Evaluation<span class=\"badge badge-primary badge-pill\">8</span></a>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihb2pZT986-d",
        "colab_type": "text"
      },
      "source": [
        "<a id='libraries'></a>\n",
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMZb8nniLt6g",
        "colab_type": "text"
      },
      "source": [
        "Remarque : pour des raisons de compatibilitÃ© : Ã  la place de plotly : \n",
        "- use plotly 4.0.0\n",
        "- install chart_studio\n",
        "- in the cufflinks config files: _init_.py, plotlytools.py, and tools.py, changes \"plotly.plotly\" to \"chart_studio.plotly\"\n",
        "\n",
        "ex en python 3.6 :\n",
        "/usr/local/lib/python3.6/dist-packages/_plotly_future_/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Co3DRJdz86-e",
        "colab_type": "code",
        "outputId": "e00896fc-b85a-4ece-d8bf-3d85ebdd54da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# !pip uninstall plotly\n",
        "# !pip uninstall cufflinks\n",
        "!pip install plotly==4.0.0\n",
        "!pip install chart_studio\n",
        "!pip install cufflinks==0.16\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import time \n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# import plotly.graph_objects as go\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "# Natural Language Tool Kit \n",
        "import nltk  \n",
        "nltk.download('stopwords') \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from collections import Counter\n",
        "import cufflinks as cf\n",
        "cf.go_offline()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/58/f3/a49d3281cc7275164ecf89ad3497556b11d9661faa119becdf7f9d3b2125/plotly-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.0.0) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.0.0) (1.3.3)\n",
            "\u001b[31mERROR: cufflinks 0.16 has requirement plotly<4.0.0a0,>=3.0.0, but you'll have plotly 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 3.10.0\n",
            "    Uninstalling plotly-3.10.0:\n",
            "      Successfully uninstalled plotly-3.10.0\n",
            "Successfully installed plotly-4.0.0\n",
            "Requirement already satisfied: chart_studio in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.3.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart_studio) (4.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (1.24.3)\n",
            "Requirement already satisfied: cufflinks==0.16 in /usr/local/lib/python3.6/dist-packages (0.16)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (7.5.1)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (1.17.4)\n",
            "Collecting plotly<4.0.0a0,>=3.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/ff/75/3982bac5076d0ce6d23103c03840fcaec90c533409f9d82c19f54512a38a/plotly-3.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (42.0.2)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.16) (0.25.3)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.16) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.16) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.16) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.16) (4.6.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks==0.16) (2.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks==0.16) (4.4.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks==0.16) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks==0.16) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks==0.16) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks==0.16) (1.0.18)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (1.3.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (2018.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->cufflinks==0.16) (2.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks==0.16) (4.6.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks==0.16) (2.6.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (5.2.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks==0.16) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks==0.16) (4.5.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.3.0->cufflinks==0.16) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.3.0->cufflinks==0.16) (0.1.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly<4.0.0a0,>=3.0.0->cufflinks==0.16) (1.24.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (2.10.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks==0.16) (17.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (1.1.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks==0.16) (0.5.1)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 4.0.0\n",
            "    Uninstalling plotly-4.0.0:\n",
            "      Successfully uninstalled plotly-4.0.0\n",
            "Successfully installed plotly-3.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDtmmmXL86-j",
        "colab_type": "text"
      },
      "source": [
        "<a id='load'></a>\n",
        "# 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETPxbRV_bLPf",
        "colab_type": "code",
        "outputId": "ed7eb5cd-f642-47b8-b2d5-e1d78df1e28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pwd\n",
        "# !rm train.csv\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "sample_data  sample_submission.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "BMU4ZLg086-l",
        "colab_type": "code",
        "outputId": "8863d1f3-479d-4daa-f4cb-3bae8cf55627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "source": [
        "\n",
        "# train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
        "# train = pd.read_csv(\"https://www.kaggle.com/c/nlp-getting-started/download/jkgYvkO3wssyod4THUn8%2Fversions%2FzgYOOcJ9rQDp8lZbDK1b%2Ffiles%2Ftrain.csv\")\n",
        "\n",
        "!wget https://drive.google.com/open?id=16NNzVBwrwizweYrnYm8--mR4i2jEXFhs -O train.csv\n",
        "# fname = \"open?id=16NNzVBwrwizweYrnYm8--mR4i2jEXFhs\"\n",
        "fname = \"train.csv\"\n",
        "fid = open(fname, 'r')\n",
        "train=pd.read_csv(fname,sep=',',engine='python',warn_bad_lines= True)\n",
        "fid.close()\n",
        "\n",
        "\n",
        "# pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None,  header='infer', names=None,  index_col=None, usecols=None, squeeze=False,  ..., engine=None, ...)\n",
        "\n",
        "\n",
        "\n",
        "# test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n",
        "# test = pd.read_csv(\"https://www.kaggle.com/c/nlp-getting-started/download/jkgYvkO3wssyod4THUn8%2Fversions%2FzgYOOcJ9rQDp8lZbDK1b%2Ffiles%2Ftest.csv\")\n",
        "\n",
        "!wget https://drive.google.com/open?id=1R8Tz3f-V4xTtz0S8nLgBewR_qxq9BqnB -O test.csv \n",
        "# fname = \"open?id=1R8Tz3f-V4xTtz0S8nLgBewR_qxq9BqnB\"\n",
        "fname = \"test.csv\"\n",
        "fid = open(fname, 'r')\n",
        "test=pd.read_csv(fname,sep=',',quoting=0,quotechar='#',engine='python',error_bad_lines= False,encoding='utf-8')\n",
        "fid.close()\n",
        "\n",
        "\n",
        "# submission =  pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
        "# submission =  pd.read_csv(\"https://www.kaggle.com/c/nlp-getting-started/download/jkgYvkO3wssyod4THUn8%2Fversions%2FzgYOOcJ9rQDp8lZbDK1b%2Ffiles%2Fsample_submission.csv\")\n",
        "\n",
        "!wget https://drive.google.com/open?id=1mhiWGwrFd7uy-shbwXvAQmjtJvsUoASi -O sample_submission.csv\n",
        "# fname = \"open?id=1mhiWGwrFd7uy-shbwXvAQmjtJvsUoASi\"\n",
        "fname = \"sample_submission.csv\"\n",
        "fid = open(fname, 'r')\n",
        "submission=pd.read_csv(fname,sep=',',quoting=0,quotechar='#',engine='python',error_bad_lines= False,encoding='utf-8')\n",
        "fid.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-30 15:31:54--  https://drive.google.com/open?id=16NNzVBwrwizweYrnYm8--mR4i2jEXFhs\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.129.113, 74.125.129.102, 74.125.129.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.129.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 OK\n",
            "Location: https://drive.google.com/file/d/16NNzVBwrwizweYrnYm8--mR4i2jEXFhs/view?usp=drive_open [following]\n",
            "--2019-12-30 15:31:54--  https://drive.google.com/file/d/16NNzVBwrwizweYrnYm8--mR4i2jEXFhs/view?usp=drive_open\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: â€˜train.csvâ€™\n",
            "\n",
            "train.csv               [ <=>                ]  67.50K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2019-12-30 15:31:55 (18.9 MB/s) - â€˜train.csvâ€™ saved [69120]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   2932\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2933\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2934\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: ',' expected after '\"'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-434d6d557c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0;34m' \"python-fwf\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 )\n\u001b[0;32m-> 1147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_original_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m         ) = self._infer_columns()\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m         \u001b[0;31m# Now self.columns has the set of columns that we will process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m                     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_pos\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_buffered_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_for_bom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2873\u001b[0;31m                 \u001b[0morig_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2874\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   2954\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\". \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2956\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alert_malformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2957\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_alert_malformed\u001b[0;34m(self, msg, row_num)\u001b[0m\n\u001b[1;32m   2912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mParserError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m             \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Skipping line {row_num}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: ',' expected after '\"'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf8UGeYOZQjA",
        "colab_type": "code",
        "outputId": "ebb78c4d-ac3e-4547-ee3c-a0d6ae8f1b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os import listdir\n",
        "listdir(\"/content/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'train.csv', 'sample_submission.csv', 'test.csv', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aPhiwy-386-o",
        "colab_type": "code",
        "outputId": "448252cb-701d-406c-85fd-0b263ddbce41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>null</th>\n",
              "      <th>1</th>\n",
              "      <th>null.1</th>\n",
              "      <th>0</th>\n",
              "      <th>1]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">NaN</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">NaN</th>\n",
              "      <th>1</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>[null</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>https://accounts.google.com/ServiceLogin?servi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <th>1</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>https://docs.google.com</th>\n",
              "      <th>NaN</th>\n",
              "      <td>1</td>\n",
              "      <td>[null</td>\n",
              "      <td>0]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[\"https://youtube.googleapis.com\"</th>\n",
              "      <th>NaN</th>\n",
              "      <th>2]</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>1</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>1</th>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[0</td>\n",
              "      <td>0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>]</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                    Unnamed: 0  ...    1]\n",
              "NaN NaN                               1   NaN NaN [null NaN                     NaN        NaN  ...    1]\n",
              "                                      NaN 1   NaN NaN   https://docs.google.com NaN          1  ...  None\n",
              "    [\"https://youtube.googleapis.com\" NaN 2]  NaN NaN   NaN                     NaN       None  ...  None\n",
              "    NaN                               NaN 1   NaN NaN   1                       1          NaN  ...    0]\n",
              "]   NaN                               NaN NaN NaN NaN   NaN                     NaN       None  ...  None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a03NL-4N86-q",
        "colab_type": "text"
      },
      "source": [
        "<ul style=\"list-style-type:square;\">\n",
        "  <li><span class=\"label label-default\">id</span> a unique identifier for each tweet</li>\n",
        "  <li><span class=\"label label-default\">text </span> the text of the tweet</li>\n",
        "  <li><span class=\"label label-default\">location</span>  the location the tweet was sent from (may be blank)</li>\n",
        "    <li><span class=\"label label-default\">keyword</span>  a particular keyword from the tweet (may be blank)</li>\n",
        "    <li><span class=\"label label-default\">target</span>  in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6NJB4Var86-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "gza2xzP986-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(HTML(f\"\"\"\n",
        "   \n",
        "        <ul class=\"list-group\">\n",
        "          <li class=\"list-group-item disabled\" aria-disabled=\"true\"><h4>Shape of Train and Test Dataset</h4></li>\n",
        "          <li class=\"list-group-item\"><h4>Number of rows in Train dataset is: <span class=\"label label-primary\">{ train.shape[0]:,}</span></h4></li>\n",
        "          <li class=\"list-group-item\"> <h4>Number of columns Train dataset is <span class=\"label label-primary\">{train.shape[1]}</span></h4></li>\n",
        "          <li class=\"list-group-item\"><h4>Number of rows in Test dataset is: <span class=\"label label-success\">{ test.shape[0]:,}</span></h4></li>\n",
        "          <li class=\"list-group-item\"><h4>Number of columns Test dataset is <span class=\"label label-success\">{test.shape[1]}</span></h4></li>\n",
        "        </ul>\n",
        "  \n",
        "    \"\"\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kPICxH-s86-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsrRUUdU86-y",
        "colab_type": "text"
      },
      "source": [
        "<a id='visual'></a>\n",
        "# 3. Visualization of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y9z50l-886-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing = train.isnull().sum()  \n",
        "missing[missing>0].sort_values(ascending=False).iplot(kind='bar',title='Null values present in train Dataset', color=['red'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q0uGMiEU86-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.target.value_counts().iplot(kind='bar',text=['Fake', 'Real'], title='Comparing Tweet is a real disaster (1) or not (0)',color=['blue'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "NttuVtgw86-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts_train = train.target.value_counts(sort=False)\n",
        "labels = counts_train.index\n",
        "values_train = counts_train.values\n",
        "\n",
        "data = go.Pie(labels=labels, values=values_train ,pull=[0.03, 0])\n",
        "layout = go.Layout(title='Comparing Tweet is a real disaster (1) or not (0) in %')\n",
        "\n",
        "fig = go.Figure(data=[data], layout=layout)\n",
        "fig.update_traces(hole=.3, hoverinfo=\"label+percent+value\")\n",
        "fig.update_layout(\n",
        "    # Add annotations in the center of the donut pies.\n",
        "    annotations=[dict(text='Train', x=0.5, y=0.5, font_size=20, showarrow=False)])\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aTKj03pq86-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['length'] = train['text'].apply(len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "HkdnrZv886-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [\n",
        "    go.Box(\n",
        "        y=train[train['target']==0]['length'],\n",
        "        name='Fake'\n",
        "    ),\n",
        "    go.Box(\n",
        "        y=train[train['target']==1]['length'],\n",
        "        name='Real'\n",
        "    )\n",
        "]\n",
        "layout = go.Layout(\n",
        "    title = 'Comparison of text length in Tweets '\n",
        ")\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "o1-WEurj86_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('The max len of text',len(train.text.max()))\n",
        "print('The min len of text is',len(train.text.min()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GiV3JORL86_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.keyword.nunique()  # Total of 221 unique keywords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sN2KKV7986_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train.keyword.value_counts()[:20].iplot(kind='bar', title='Top 20 keywords in text', color='red')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jPGRXzba86_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.location.value_counts()[:20].iplot(kind='bar', title='Top 20 location in tweet', color='blue')  # Check the top 15 locations "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5G6Uz9V86_M",
        "colab_type": "text"
      },
      "source": [
        " <a id='word'></a>\n",
        "#  4. WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zOUhhqIz86_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOPWORDS.add('https')  # remove htps to the world Cloud\n",
        "\n",
        "def Plot_world(text):\n",
        "    \n",
        "    comment_words = ' '\n",
        "    stopwords = set(STOPWORDS) \n",
        "    \n",
        "    for val in text: \n",
        "\n",
        "        # typecaste each val to string \n",
        "        val = str(val) \n",
        "\n",
        "        # split the value \n",
        "        tokens = val.split() \n",
        "\n",
        "        # Converts each token into lowercase \n",
        "        for i in range(len(tokens)): \n",
        "            tokens[i] = tokens[i].lower() \n",
        "\n",
        "        for words in tokens: \n",
        "            comment_words = comment_words + words + ' '\n",
        "\n",
        "\n",
        "    wordcloud = WordCloud(width = 5000, height = 4000, \n",
        "                    background_color ='black', \n",
        "                    stopwords = stopwords, \n",
        "                    min_font_size = 10).generate(comment_words) \n",
        "\n",
        "    # plot the WordCloud image                        \n",
        "    plt.figure(figsize = (12, 12), facecolor = 'k', edgecolor = 'k' ) \n",
        "    plt.imshow(wordcloud) \n",
        "    plt.axis(\"off\") \n",
        "    plt.tight_layout(pad = 0) \n",
        "\n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ccD3omSi86_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-1sPW2U286_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = train.text.values\n",
        "\n",
        "Plot_world(text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3EXKutZ86_X",
        "colab_type": "text"
      },
      "source": [
        "<a id='clean'></a>\n",
        "# 5. Cleaning the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jAKe_2m386_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#How many http words has this text?\n",
        "train.loc[train['text'].str.contains('http')].target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J5-0wC7u86_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "\n",
        "def remove_html(text):\n",
        "    no_html= pattern.sub('',text)\n",
        "    return no_html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GiizJjSu86_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all text that start with html\n",
        "train['text']=train['text'].apply(lambda x : remove_html(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4dtc1z5V86_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets check if this clean works\n",
        "train.loc[train['text'].str.contains('http')].target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wlrnEK7986_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all text that start with html in test\n",
        "test['text']=test['text'].apply(lambda x : remove_html(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxQL3j0h86_p",
        "colab_type": "text"
      },
      "source": [
        "### Now remove stopwords, pass to lower add delimiter and more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DKipSOsu86_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        " \n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)  \n",
        "\n",
        "    text = text.lower()  \n",
        "\n",
        "    # split to array(default delimiter is \" \") \n",
        "    text = text.split()  \n",
        "    \n",
        "    text = [w for w in text if not w in set(stopwords.words('english'))] \n",
        "\n",
        "    text = ' '.join(text)    \n",
        "            \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KQkpnhTz86_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = train.text[3]\n",
        "print(text)\n",
        "clean_text(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4AYpEtpA86_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply clean text \n",
        "train['text'] = train['text'].apply(lambda x : clean_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "87H9ScHH86_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply clean text \n",
        "test['text']=test['text'].apply(lambda x : clean_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1_9uN0m586_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many unique words have this text\n",
        "def counter_word (text):\n",
        "    count = Counter()\n",
        "    for i in text.values:\n",
        "        for word in i.split():\n",
        "            count[word] += 1\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wx9uMO9Q86_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_values = train[\"text\"]\n",
        "\n",
        "counter = counter_word(text_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w8nBGM8M86_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"The len of unique words is: {len(counter)}\")\n",
        "list(counter.items())[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3LT-5Md87AA",
        "colab_type": "text"
      },
      "source": [
        "<a id='split'></a>\n",
        "# 6. Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jZVo4vV_87AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "\n",
        "vocab_size = len(counter)\n",
        "embedding_dim = 32\n",
        "\n",
        "# Max number of words in each complaint.\n",
        "max_length = 20\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "\n",
        "# oov_took its set for words out our word index\n",
        "oov_tok = \"<XXX>\"\n",
        "training_size = 6090\n",
        "seq_len = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c2PLEB8z87AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is base in 80% of the data, an only text and targert at this moment\n",
        "\n",
        "training_sentences = train.text[0:training_size]\n",
        "training_labels = train.target[0:training_size]\n",
        "\n",
        "testing_sentences = train.text[training_size:]\n",
        "testing_labels = train.target[training_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jo_PzHT687AG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print('The Shape of training ',training_sentences.shape)\n",
        "print('The Shape of testing',testing_sentences.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pVlcHYRf87AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d0lrI8N087AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QzYYxIep87AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets see the first 10 elements\n",
        "print(\"THe first word Index are: \")\n",
        "for x in list(word_index)[0:15]:\n",
        "    print (\" {},  {} \".format(x,  word_index[x]))\n",
        "\n",
        "# If you want to see completed -> word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p0LLj_yh87AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cIQX2ufd87AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train.text[1])\n",
        "print(training_sequences[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5imyovGX87AU",
        "colab_type": "text"
      },
      "source": [
        "## check Inverse for see how it works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "Le3IKIl987AV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "stbjzlk-87AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets see the first 10 elements\n",
        "print(\"THe first reverse word Index are: \")\n",
        "for x in list(reverse_word_index)[0:15]:\n",
        "    print (\" {},  {} \".format(x,  reverse_word_index[x]))\n",
        "\n",
        "# If you want to see completed -> reverse_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Yr7rGQcF87Ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wVbj27Yk87Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode(training_sequences[1]) # this can be usefull for check predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BxFkMDgJ87Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_padded[1628]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cuOmIk8v87At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QraiuUe_87Av",
        "colab_type": "text"
      },
      "source": [
        "<a id='model'></a>\n",
        "# 7. Creating the Model\n",
        "\n",
        "    # For a binary classification problem\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "                                    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GNJWubDV87Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Definition with LSTM\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # remember this is a binary clasification\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QuBxMHur87Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bNlEoB9J87Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6mCrQ1y187A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 10\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels))\n",
        "\n",
        "final_time = (time.time()- start_time)/60\n",
        "print(f'The time in minutos: {final_time}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lQWWhf0b87A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LE2101gr87A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_loss[['accuracy','val_accuracy']].plot(ylim=[0,1]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT48Vy4n87A6",
        "colab_type": "text"
      },
      "source": [
        "<a id='eval'></a>\n",
        "# 8. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rqB6xs2t87A7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict_classes(testing_padded)   # predict_ clases because is classification problem with the split test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I9GERcRh87A9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rOWuOe5x87A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yroKH55D87BA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Showing Confusion Matrix\n",
        "def plot_cm(y_true, y_pred, title, figsize=(5,4)):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "            elif c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    plt.title(title)\n",
        "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SQ0XmKLM87BC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Showing Confusion Matrix\n",
        "plot_cm(testing_labels,predictions, 'Confution matrix of Tweets', figsize=(7,7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SyqAHyN87BE",
        "colab_type": "text"
      },
      "source": [
        "# Now working with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "89A8h2xi87BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "testing_sequences2 = tokenizer.texts_to_sequences(test.text)\n",
        "testing_padded2 = pad_sequences(testing_sequences2, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kjAiGHIT87BH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(testing_padded2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uczoVFva87BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample of submission\n",
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_BUpRkK587BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['target'] = (predictions > 0.5).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r7zW3kun87BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oKEPmIJH87BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(\"submission.csv\", index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HODFhsR87BX",
        "colab_type": "text"
      },
      "source": [
        "<h2>I hope this notebook <span style=\"color:red\">Usefull</span> for you! </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrbEFcTv87BX",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top\" class=\"btn btn-primary btn-lg active\" role=\"button\" aria-pressed=\"true\">Go to TOP</a>\n"
      ]
    }
  ]
}